{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFKS7dgnPQWw88AH3x8mXt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abadabada/MachineLearningMiniProject/blob/main/MachineLearningMiniProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Machine Learning Mini-Project: Pixel-Aligned Implicit Function for High-Resolution 3D Human Digitization (PIFuHD)**"
      ],
      "metadata": {
        "id": "PpaJdVLdZxBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this project, I am working with the Multi-Level Pixel-Aligned Implicit Function for\n",
        "High-Resolution 3D Human Digitization (PIFuHD). This ML-based application takes a PNG or JPEG of a clothed human as an input, then produces a 3D model based on the picture as an OBJ file.\n",
        "\n",
        "\n",
        "This model uses Deep Learning and more specifically convolutional neural networks (CNN) to create the 3d objects. This technique is perfect for this model since it uses Images as an input and doesn't produce any 3D data during processing whichc makes it very memory efficient. Althought since this is still a CNN I chose to run in google colab due to it's heavy requirment of GPU. This model first uses a Lightweight Human Pose Estimation, then the image is cropped to a 512x512 rect version. After this the result picture is used as an input in the PIFu model. The PIFu model then also creates a height map picture of the back and the front to help with determining the positon of the 3D points in space for a higher resolution.\n",
        "\n",
        "\n",
        "Since I am using Deep Learning, extraction techniques aren't required.\n",
        "\n",
        "\n",
        "I'm also using a premade large scale data set provided by the creators of the model. This data set is generated by scanning numorous high quality 3d human meshes and it is used to train the model in an end-to-end fashion.\n",
        "\n",
        "\n",
        "To evalutate this system, I will be using different picture types than just front portaits of humans. I still will be keep it into the humanoid category, by using either CG characters, like aliens or 3d characters from movies or games, and also testing it with drawn characters, and also mix in using different shapes and angles of these characters to see how well the model will handle such input.\n",
        "\n",
        "My only original contribution to this project is choosing the input and testing with it various times to see if there will be any variety in the output from the same image, else the code is mostly from the PIFu Github repository and the data set is also provided with that."
      ],
      "metadata": {
        "id": "sDoEko06rN8q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mounting Google Drive to Google Colab Notebook**"
      ],
      "metadata": {
        "id": "wayhraGQvVwm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOKDBRC0Yzs6",
        "outputId": "1fa654b4-253e-4600-8c7f-9493c3367820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PIFuHD Repository**\n",
        "\n"
      ],
      "metadata": {
        "id": "hDWr1dyQaAN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/pifuhd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYSjM5iaZuLQ",
        "outputId": "1d39a5e8-e704-4a60-dbe2-431d5f1282e9"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'pifuhd' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input Data & Output Path**"
      ],
      "metadata": {
        "id": "A-jfBXY6G9p5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/pifuhd/sample_images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT3qvHlEGy_9",
        "outputId": "4a2d1dd0-acee-4dc1-9ad2-3a7c2e21e874"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pifuhd/sample_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "image_path = '/content/pifuhd/sample_images/Shrek.png' # example image\n",
        "image_dir = os.path.dirname(image_path)\n",
        "file_name = os.path.splitext(os.path.basename(image_path))[0]\n",
        "\n",
        "#output path\n",
        "obj_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.obj' % file_name\n",
        "out_img_path = '/content/pifuhd/results/pifuhd_final/recon/result_%s_256.png' % file_name"
      ],
      "metadata": {
        "id": "KjVEwVIbKRtA"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unZMJKR_K5bO",
        "outputId": "18bcbc03-5c62-4980-9787-f761a72e4b95"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Cripping & Human Pose Estimation Training Model**"
      ],
      "metadata": {
        "id": "NS4J1LSkLAXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Daniil-Osokin/lightweight-human-pose-estimation.pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WCRPAD1LDuB",
        "outputId": "81bb6a8f-547e-4cd6-df7d-c7df716fc9be"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'lightweight-human-pose-estimation.pytorch' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/lightweight-human-pose-estimation.pytorch/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_371ErwLGpb",
        "outputId": "196b08fa-23fb-4aa0-9020-4eb2c3a58bdd"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/lightweight-human-pose-estimation.pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVOUGglKLJG0",
        "outputId": "31492ca0-e3eb-47f3-b4e4-fd3cd6c9c2e7"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-13 09:01:11--  https://download.01.org/opencv/openvino_training_extensions/models/human_pose_estimation/checkpoint_iter_370000.pth\n",
            "Resolving download.01.org (download.01.org)... 104.87.100.39, 2600:1413:b000:38e::4b21, 2600:1413:b000:389::4b21\n",
            "Connecting to download.01.org (download.01.org)|104.87.100.39|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87959810 (84M) [application/octet-stream]\n",
            "Saving to: ‘checkpoint_iter_370000.pth.12’\n",
            "\n",
            "checkpoint_iter_370 100%[===================>]  83.88M   301MB/s    in 0.3s    \n",
            "\n",
            "2023-02-13 09:01:12 (301 MB/s) - ‘checkpoint_iter_370000.pth.12’ saved [87959810/87959810]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import cv2\n",
        "import numpy as np\n",
        "from models.with_mobilenet import PoseEstimationWithMobileNet\n",
        "from modules.keypoints import extract_keypoints, group_keypoints\n",
        "from modules.load_state import load_state\n",
        "from modules.pose import Pose, track_poses\n",
        "import demo\n",
        "\n",
        "def get_rect(net, images, height_size):\n",
        "    net = net.eval()\n",
        "\n",
        "    stride = 8\n",
        "    upsample_ratio = 4\n",
        "    num_keypoints = Pose.num_kpts\n",
        "    previous_poses = []\n",
        "    delay = 33\n",
        "    for image in images:\n",
        "        rect_path = image.replace('.%s' % (image.split('.')[-1]), '_rect.txt')\n",
        "        img = cv2.imread(image, cv2.IMREAD_COLOR)\n",
        "        orig_img = img.copy()\n",
        "        orig_img = img.copy()\n",
        "        heatmaps, pafs, scale, pad = demo.infer_fast(net, img, height_size, stride, upsample_ratio, cpu=False)\n",
        "\n",
        "        total_keypoints_num = 0\n",
        "        all_keypoints_by_type = []\n",
        "        for kpt_idx in range(num_keypoints):  # 19th for bg\n",
        "            total_keypoints_num += extract_keypoints(heatmaps[:, :, kpt_idx], all_keypoints_by_type, total_keypoints_num)\n",
        "\n",
        "        pose_entries, all_keypoints = group_keypoints(all_keypoints_by_type, pafs)\n",
        "        for kpt_id in range(all_keypoints.shape[0]):\n",
        "            all_keypoints[kpt_id, 0] = (all_keypoints[kpt_id, 0] * stride / upsample_ratio - pad[1]) / scale\n",
        "            all_keypoints[kpt_id, 1] = (all_keypoints[kpt_id, 1] * stride / upsample_ratio - pad[0]) / scale\n",
        "        current_poses = []\n",
        "\n",
        "        rects = []\n",
        "        for n in range(len(pose_entries)):\n",
        "            if len(pose_entries[n]) == 0:\n",
        "                continue\n",
        "            pose_keypoints = np.ones((num_keypoints, 2), dtype=np.int32) * -1\n",
        "            valid_keypoints = []\n",
        "            for kpt_id in range(num_keypoints):\n",
        "                if pose_entries[n][kpt_id] != -1.0:  # keypoint was found\n",
        "                    pose_keypoints[kpt_id, 0] = int(all_keypoints[int(pose_entries[n][kpt_id]), 0])\n",
        "                    pose_keypoints[kpt_id, 1] = int(all_keypoints[int(pose_entries[n][kpt_id]), 1])\n",
        "                    valid_keypoints.append([pose_keypoints[kpt_id, 0], pose_keypoints[kpt_id, 1]])\n",
        "            valid_keypoints = np.array(valid_keypoints)\n",
        "            \n",
        "            if pose_entries[n][10] != -1.0 or pose_entries[n][13] != -1.0:\n",
        "              pmin = valid_keypoints.min(0)\n",
        "              pmax = valid_keypoints.max(0)\n",
        "\n",
        "              center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.int)\n",
        "              radius = int(0.65 * max(pmax[0]-pmin[0], pmax[1]-pmin[1]))\n",
        "            elif pose_entries[n][10] == -1.0 and pose_entries[n][13] == -1.0 and pose_entries[n][8] != -1.0 and pose_entries[n][11] != -1.0:\n",
        "              # if leg is missing, use pelvis to get cropping\n",
        "              center = (0.5 * (pose_keypoints[8] + pose_keypoints[11])).astype(np.int)\n",
        "              radius = int(1.45*np.sqrt(((center[None,:] - valid_keypoints)**2).sum(1)).max(0))\n",
        "              center[1] += int(0.05*radius)\n",
        "            else:\n",
        "              center = np.array([img.shape[1]//2,img.shape[0]//2])\n",
        "              radius = max(img.shape[1]//2,img.shape[0]//2)\n",
        "\n",
        "            x1 = center[0] - radius\n",
        "            y1 = center[1] - radius\n",
        "\n",
        "            rects.append([x1, y1, 2*radius, 2*radius])\n",
        "\n",
        "        np.savetxt(rect_path, np.array(rects), fmt='%d')"
      ],
      "metadata": {
        "id": "ZotKFOymLMWH"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net = PoseEstimationWithMobileNet()\n",
        "checkpoint = torch.load('checkpoint_iter_370000.pth', map_location='cpu')\n",
        "load_state(net, checkpoint)\n",
        "\n",
        "get_rect(net.cuda(), [image_path], 512)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtCvnCEvLfUJ",
        "outputId": "ebe1fbff-e063-4c28-ef9c-85f0bba2cbe7"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-146-1919f42bf24c>:53: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  center = (0.5 * (pmax[:2] + pmin[:2])).astype(np.int)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pretrained Model**"
      ],
      "metadata": {
        "id": "AaSmUV8rLpDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/pifuhd/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVFo9MGTLkME",
        "outputId": "12dfa2bd-ce12-41fc-974f-5718d6c0f980"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pifuhd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sh ./scripts/download_trained_model.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6wleZClLtSY",
        "outputId": "f7a45e01-0e67-4b34-c45e-8e63bcf971b0"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ mkdir -p checkpoints\n",
            "+ cd checkpoints\n",
            "+ wget https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt pifuhd.pt\n",
            "--2023-02-13 09:01:12--  https://dl.fbaipublicfiles.com/pifuhd/checkpoints/pifuhd.pt\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1548375177 (1.4G) [application/octet-stream]\n",
            "Saving to: ‘pifuhd.pt.2’\n",
            "\n",
            "pifuhd.pt.2         100%[===================>]   1.44G  16.5MB/s    in 93s     \n",
            "\n",
            "2023-02-13 09:02:47 (15.8 MB/s) - ‘pifuhd.pt.2’ saved [1548375177/1548375177]\n",
            "\n",
            "--2023-02-13 09:02:47--  http://pifuhd.pt/\n",
            "Resolving pifuhd.pt (pifuhd.pt)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘pifuhd.pt’\n",
            "FINISHED --2023-02-13 09:02:47--\n",
            "Total wall clock time: 1m 35s\n",
            "Downloaded: 1 files, 1.4G in 1m 33s (15.8 MB/s)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Running PIHuHD & Output Data**"
      ],
      "metadata": {
        "id": "qZJum1W0NtjA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m apps.simple_test -r 256 --use_rect -i $image_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef1x_w0ILyYP",
        "outputId": "08063cb2-8a65-4f21-c487-4a573e4a830f"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming from  ./checkpoints/pifuhd.pt\n",
            "Warning: opt is overwritten.\n",
            "test data size:  4\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "generate mesh (test) ...\n",
            "  0% 0/4 [00:00<?, ?it/s]./results/pifuhd_final/recon/result_JohnCena_256.obj\n",
            "/content/pifuhd/lib/mesh_util.py:77: FutureWarning: marching_cubes_lewiner is deprecated in favor of marching_cubes. marching_cubes_lewiner will be removed in version 0.19\n",
            "  verts, faces, normals, values = measure.marching_cubes_lewiner(sdf, thresh)\n",
            " 25% 1/4 [00:10<00:31, 10.60s/it]./results/pifuhd_final/recon/result_Shrek_256.obj\n",
            " 50% 2/4 [00:19<00:19,  9.67s/it]./results/pifuhd_final/recon/result_alien_256.obj\n",
            " 75% 3/4 [00:25<00:07,  7.99s/it]./results/pifuhd_final/recon/result_test_256.obj\n",
            "100% 4/4 [00:31<00:00,  7.82s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "VH2xoHq3OMbx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0SLu1zb6NxvQ"
      },
      "execution_count": 150,
      "outputs": []
    }
  ]
}